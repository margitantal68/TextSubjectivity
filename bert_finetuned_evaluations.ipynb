{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of our BERT-based fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL_NAME = \"bert-base-uncased\"\n",
    "SAVED_MODEL_NAME = 'models/bert-finetuned-30-epochs.sd'\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "FINE_TUNING = True\n",
    "\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "VAL_BATCH_SIZE = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import logging, AutoTokenizer, AutoModel\n",
    "\n",
    "# instantiate tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "# load BERT model\n",
    "dbert_pt = AutoModel.from_pretrained(BASE_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "num_classes = 2\n",
    "\n",
    "class BertClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BertClassification, self).__init__()\n",
    "        self.dbert = dbert_pt\n",
    "        self.num_classes = 2\n",
    "        self.linear = nn.Linear(dbert_pt.config.hidden_size, num_classes)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dbert(input_ids=x)\n",
    "        x = x[\"last_hidden_state\"][:,0,:]\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load saved model parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from:  models/bert-finetuned-30-epochs.sd\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertClassification(\n",
       "  (dbert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Loading model from: \", SAVED_MODEL_NAME)\n",
    "model_pt = BertClassification().to(device)\n",
    "model_pt.load_state_dict(torch.load(SAVED_MODEL_NAME))\n",
    "model_pt.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to torch dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X, y as Torch tensors\n",
    "        \"\"\"\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y_train)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_train[idx], self.y_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.AdamW(model_pt.parameters(), lr=1e-5, weight_decay=0.01)\n",
    "\n",
    "\n",
    "def evaluate_model(model_pt, dataloader):\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    valid_accuracy = []\n",
    "    valid_loss = 0.0\n",
    "    for X, y in dataloader:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device) \n",
    "        prediction = model_pt(X)\n",
    "        loss = criterion(prediction, y)\n",
    "\n",
    "        valid_loss += loss.item()\n",
    "            \n",
    "        prediction_index = prediction.argmax(axis=1)\n",
    "        accuracy = (prediction_index==y)\n",
    "        \n",
    "        label_list = y.tolist()\n",
    "        predicted_label_list = prediction_index.tolist()\n",
    "\n",
    "        for i in range(len(label_list)):\n",
    "            if label_list[i] == 1:\n",
    "                if predicted_label_list[i] == 1:\n",
    "                    TP += 1\n",
    "                else:\n",
    "                    FN += 1\n",
    "            else:\n",
    "                if predicted_label_list[i] == 0:\n",
    "                    TN += 1\n",
    "                else:\n",
    "                    FP += 1\n",
    "                # print(label_list,'-->', predicted_label_list)\n",
    "        valid_accuracy += accuracy\n",
    "    valid_accuracy = (sum(valid_accuracy) / len(valid_accuracy)).item()\n",
    "\n",
    "    print('TP:', TP)\n",
    "    print('FN:', FN)\n",
    "    print('FP:', FP)\n",
    "    print('TN:', TN)\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    F1 = 2 * precision * recall / (precision + recall)\n",
    "    print(\"accuracy: {:10.4f}\".format(valid_accuracy)) \n",
    "    print('precision: {:10.4f}'.format(precision))\n",
    "    print('recall: {:10.4f}'.format(recall))\n",
    "    print('F1: {:10.4f}'.format(F1))\n",
    "    print('{:10.4f},{:10.4f},{:10.4f},{:10.4f}'.format(valid_accuracy, precision, recall, F1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Evaluate on SUBJ Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data/SUBJ/test.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 485\n",
      "FN: 15\n",
      "FP: 12\n",
      "TN: 488\n",
      "accuracy:     0.9730\n",
      "precision:     0.9759\n",
      "recall:     0.9700\n",
      "F1:     0.9729\n",
      "    0.9730,    0.9759,    0.9700,    0.9729\n"
     ]
    }
   ],
   "source": [
    "labels = df['label'].to_list()\n",
    "texts = df['text'].to_list()\n",
    "\n",
    "texts = tokenizer(texts, padding='max_length', max_length = 256, truncation=True,  return_tensors='pt')[\"input_ids\"]\n",
    "labels = torch.Tensor(labels).long()\n",
    "\n",
    "dataset = MyDataset(texts, labels)\n",
    "test_dataloader = DataLoader(dataset, batch_size=TRAIN_BATCH_SIZE)\n",
    "\n",
    "evaluate_model(model_pt, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Evaluate on tasksource**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/tasksource/test.csv')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {\"SUBJ\": 1, \"OBJ\": 0}\n",
    "\n",
    "# tasksource\n",
    "# remove the last column from a dataframe\n",
    "df = df.iloc[:, :-1]\n",
    "# rename the first column of the dataframe\n",
    "df = df.rename(columns={\"Sentence\": \"text\", \"Label\": \"label\"})\n",
    "\n",
    "\n",
    "def encode_labels(example):\n",
    "    example[\"label\"] = label2id[example[\"label\"]]\n",
    "    return example\n",
    "\n",
    "df['label'] = df['label'].apply(lambda x: label2id[x])\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 45\n",
      "FN: 68\n",
      "FP: 17\n",
      "TN: 89\n",
      "accuracy:     0.6119\n",
      "precision:     0.7258\n",
      "recall:     0.3982\n",
      "F1:     0.5143\n",
      "    0.6119,    0.7258,    0.3982,    0.5143\n"
     ]
    }
   ],
   "source": [
    "labels = df['label'].to_list()\n",
    "texts = df['text'].to_list()\n",
    "\n",
    "texts = tokenizer(texts, padding='max_length', max_length = 256, truncation=True,  return_tensors='pt')[\"input_ids\"]\n",
    "labels = torch.Tensor(labels).long()\n",
    "\n",
    "dataset = MyDataset(texts, labels)\n",
    "test_dataloader = DataLoader(dataset, batch_size=TRAIN_BATCH_SIZE)\n",
    "\n",
    "evaluate_model(model_pt, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Evaluate on Bard dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data/bard.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 33\n",
      "FN: 17\n",
      "FP: 0\n",
      "TN: 50\n",
      "accuracy:     0.8300\n",
      "precision:     1.0000\n",
      "recall:     0.6600\n",
      "F1:     0.7952\n",
      "    0.8300,    1.0000,    0.6600,    0.7952\n"
     ]
    }
   ],
   "source": [
    "labels = df['label'].to_list()\n",
    "texts = df['text'].to_list()\n",
    "\n",
    "texts = tokenizer(texts, padding='max_length', max_length = 256, truncation=True,  return_tensors='pt')[\"input_ids\"]\n",
    "labels = torch.Tensor(labels).long()\n",
    "\n",
    "dataset = MyDataset(texts, labels)\n",
    "test_dataloader = DataLoader(dataset, batch_size=TRAIN_BATCH_SIZE)\n",
    "\n",
    "evaluate_model(model_pt, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Evaluate on a21.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data/ai21.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 22\n",
      "FN: 28\n",
      "FP: 0\n",
      "TN: 50\n",
      "accuracy:     0.7200\n",
      "precision:     1.0000\n",
      "recall:     0.4400\n",
      "F1:     0.6111\n",
      "    0.7200,    1.0000,    0.4400,    0.6111\n"
     ]
    }
   ],
   "source": [
    "labels = df['label'].to_list()\n",
    "texts = df['text'].to_list()\n",
    "\n",
    "texts = tokenizer(texts, padding='max_length', max_length = 256, truncation=True,  return_tensors='pt')[\"input_ids\"]\n",
    "labels = torch.Tensor(labels).long()\n",
    "\n",
    "dataset = MyDataset(texts, labels)\n",
    "test_dataloader = DataLoader(dataset, batch_size=TRAIN_BATCH_SIZE)\n",
    "\n",
    "evaluate_model(model_pt, test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-sentiment-iixsuFdB-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
